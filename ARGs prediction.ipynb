{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0df5261d",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-03-18T07:51:12.388573Z",
     "iopub.status.busy": "2023-03-18T07:51:12.388086Z",
     "iopub.status.idle": "2023-03-18T07:51:22.860497Z",
     "shell.execute_reply": "2023-03-18T07:51:22.859227Z"
    },
    "papermill": {
     "duration": 10.48105,
     "end_time": "2023-03-18T07:51:22.863786",
     "exception": false,
     "start_time": "2023-03-18T07:51:12.382736",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fair-esm\r\n",
      "  Downloading fair_esm-2.0.0-py3-none-any.whl (93 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: fair-esm\r\n",
      "Successfully installed fair-esm-2.0.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install fair-esm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "230fd66c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-18T07:51:22.871597Z",
     "iopub.status.busy": "2023-03-18T07:51:22.871267Z",
     "iopub.status.idle": "2023-03-18T07:51:27.109203Z",
     "shell.execute_reply": "2023-03-18T07:51:27.108100Z"
    },
    "papermill": {
     "duration": 4.244522,
     "end_time": "2023-03-18T07:51:27.111638",
     "exception": false,
     "start_time": "2023-03-18T07:51:22.867116",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import normal\n",
    "from torch.nn.modules.linear import Linear\n",
    "import os\n",
    "import torch\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from Bio import SeqIO\n",
    "import esm\n",
    "from numpy.lib.function_base import average\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "import torch.optim as optim\n",
    "\n",
    "antibiotic_fam = {'aminoglycoside': 0, 'macrolide-lincosamide-streptogramin': 1, 'polymyxin': 2, \n",
    "            'fosfomycin': 3, 'multidrug': 7, 'bacitracin': 5, 'quinolone': 6, \n",
    "            'trimethoprim': 4, 'chloramphenicol': 8,'tetracycline': 9, 'rifampin': 10, \n",
    "            'beta_lactam': 11, 'sulfonamide': 12, 'glycopeptide': 13, 'nonarg':14}\n",
    "\n",
    "def read(file_path):\n",
    "    data = []\n",
    "    for item in SeqIO.parse(file_path, \"fasta\"):\n",
    "        if 'FEATURE' in item.id:\n",
    "            anti_class = item.description.split('|')[3]\n",
    "            y = antibiotic_fam[anti_class]\n",
    "        else:\n",
    "            y = antibiotic_fam['nonarg']\n",
    "        X = item.seq\n",
    "        data.append((y, X))\n",
    "    return data\n",
    "\n",
    "def read_test(file_path):\n",
    "    data = []\n",
    "    name_list = []\n",
    "    for item in SeqIO.parse(file_path, \"fasta\"):\n",
    "        X = item.seq\n",
    "        y = -1\n",
    "        data.append((y, X))\n",
    "        name_list.append(item.id)\n",
    "    return data, name_list\n",
    "\n",
    "data_dir = \"/kaggle/input/aist4010-spring2023-a2/data\"\n",
    "\n",
    "\n",
    "train_data = read(os.path.join(data_dir, \"train.fasta\"))\n",
    "val_data = read(os.path.join(data_dir, \"val.fasta\"))\n",
    "test_data, test_list = read_test(os.path.join(data_dir, \"test.fasta\"))\n",
    "\n",
    "if torch.cuda.is_available(): \n",
    "     device = \"cuda\" \n",
    "else: \n",
    "     device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6d413be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-18T07:51:27.119216Z",
     "iopub.status.busy": "2023-03-18T07:51:27.118645Z",
     "iopub.status.idle": "2023-03-18T07:51:27.129415Z",
     "shell.execute_reply": "2023-03-18T07:51:27.128300Z"
    },
    "papermill": {
     "duration": 0.016884,
     "end_time": "2023-03-18T07:51:27.131645",
     "exception": false,
     "start_time": "2023-03-18T07:51:27.114761",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes = 15):\n",
    "        super(Net, self).__init__()\n",
    "        self.CNN = nn.Sequential(\n",
    "                                nn.Conv1d(in_channels=128, out_channels=160, kernel_size=9),\n",
    "                                nn.ReLU(inplace=True),\n",
    "                                nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "                                nn.Conv1d(in_channels=160, out_channels=240, kernel_size=5),\n",
    "                                nn.ReLU(inplace=True),\n",
    "                                nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "                                 nn.Conv1d(in_channels=240, out_channels=240, kernel_size=5),\n",
    "                                nn.ReLU(inplace=True),\n",
    "            \n",
    "            \n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "                                        nn.Linear(1280, 1024),\n",
    "                                        nn.Sigmoid(),\n",
    "                                        nn.Linear(1024, 1024),\n",
    "                                        nn.Sigmoid(),\n",
    "                                        nn.Linear(1024, num_classes)\n",
    "                                       )\n",
    "    \n",
    "\n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self._modules:\n",
    "            if isinstance(m, Linear):\n",
    "                m.weight.data.normal_(0, 0.02)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, input):\n",
    "#         x = self.CNN(input)\n",
    "        x = input.unsqueeze(1).float()\n",
    "        x = x.view(-1, 1280)\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d90e187",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-18T07:51:27.140378Z",
     "iopub.status.busy": "2023-03-18T07:51:27.138650Z",
     "iopub.status.idle": "2023-03-18T07:51:27.144574Z",
     "shell.execute_reply": "2023-03-18T07:51:27.143642Z"
    },
    "papermill": {
     "duration": 0.012349,
     "end_time": "2023-03-18T07:51:27.147042",
     "exception": false,
     "start_time": "2023-03-18T07:51:27.134693",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load ESM model\n",
    "# model, alphabet = esm.pretrained.esm1_t34_670M_UR50D()\n",
    "# model, alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
    "# model = model.cuda()\n",
    "# converter = alphabet.get_batch_converter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e561d59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-18T07:51:27.154490Z",
     "iopub.status.busy": "2023-03-18T07:51:27.153885Z",
     "iopub.status.idle": "2023-03-18T07:51:27.158704Z",
     "shell.execute_reply": "2023-03-18T07:51:27.157614Z"
    },
    "papermill": {
     "duration": 0.011268,
     "end_time": "2023-03-18T07:51:27.161220",
     "exception": false,
     "start_time": "2023-03-18T07:51:27.149952",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def embedding(data, converter):\n",
    "#     representation = []\n",
    "#     labels, strs, tokens = converter(data)\n",
    "#     with torch.no_grad():\n",
    "#         for i in tqdm(range(0,len(tokens),20)):\n",
    "#             results = model(tokens[i:i+20].cuda(), repr_layers=[12], return_contacts=False)\n",
    "#             for j in results[\"representations\"][12]:\n",
    "#                 representation.append(j.mean(0))\n",
    "# #   Stack the tensor\n",
    "#     Xs = torch.stack(representation, dim=0).cpu()\n",
    "#     return Xs, np.array(labels)\n",
    "\n",
    "# train_X, train_y = embedding(train_data, converter)\n",
    "# train_data_esm = (train_X, train_y)\n",
    "# torch.save(train_data_esm, 'train.pt')\n",
    "# val_X, val_y  = embedding(val_data, converter)\n",
    "# val_data_esm = (val_X, val_y)\n",
    "# torch.save(val_data_esm, 'val.pt')\n",
    "\n",
    "# test_X, _ = embedding(test_data, converter)\n",
    "# torch.save(test_X, 'test.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f8de545",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-18T07:51:27.167968Z",
     "iopub.status.busy": "2023-03-18T07:51:27.167683Z",
     "iopub.status.idle": "2023-03-18T07:51:28.425725Z",
     "shell.execute_reply": "2023-03-18T07:51:28.424627Z"
    },
    "papermill": {
     "duration": 1.264267,
     "end_time": "2023-03-18T07:51:28.428336",
     "exception": false,
     "start_time": "2023-03-18T07:51:27.164069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "    def __init__(self, esm_data):\n",
    "        self.Xs = esm_data[0]\n",
    "        self.ys = esm_data[1]\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.ys)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X = self.Xs[index]\n",
    "        y = self.ys[index]\n",
    "        return (X, y)\n",
    "\n",
    "train_esm = torch.load('/kaggle/input/asm2-check-pt/aist4010 asm2/train.pt')\n",
    "val_esm = torch.load('/kaggle/input/asm2-check-pt/aist4010 asm2/val.pt')\n",
    "# train_esm = torch.load('/kaggle/working/train.pt')\n",
    "# val_esm = torch.load('/kaggle/working/val.pt')\n",
    "\n",
    "trainset = Data(train_esm)\n",
    "trainloader = DataLoader(trainset, batch_size=128, shuffle=True)\n",
    "valset = Data(val_esm)\n",
    "valloader = DataLoader(valset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57d00062",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-18T07:51:28.437196Z",
     "iopub.status.busy": "2023-03-18T07:51:28.435430Z",
     "iopub.status.idle": "2023-03-18T07:51:28.449932Z",
     "shell.execute_reply": "2023-03-18T07:51:28.448981Z"
    },
    "papermill": {
     "duration": 0.020921,
     "end_time": "2023-03-18T07:51:28.452247",
     "exception": false,
     "start_time": "2023-03-18T07:51:28.431326",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer,scheduler, num_epochs=10):\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_f1 = 0.0\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        train_loss = 0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            # forward \n",
    "            outputs = net(inputs)\n",
    "            # backward\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            pred = outputs.data.argmax(1).cpu().numpy()\n",
    "            y_pred.append(pred)\n",
    "            true = labels.data.cpu().numpy()\n",
    "            y_true.append(true)\n",
    "           \n",
    "        # train stat evaluation    \n",
    "        y_true = np.concatenate(y_true , axis=0)\n",
    "        y_pred = np.concatenate(y_pred,  axis=0)\n",
    "        train_f1 = f1_score(y_true=y_true,y_pred=y_pred, average='macro')\n",
    "        train_acc = accuracy_score(y_true,y_pred)\n",
    "        \n",
    "\n",
    "        #  Validation\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for data in valloader:\n",
    "                inputs, labels = data[0].to(device), data[1].to(device)\n",
    "                # forward \n",
    "                outputs = net(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                pred = outputs.data.argmax(1).cpu().numpy()\n",
    "                y_pred.append(pred)\n",
    "\n",
    "                true = labels.data.cpu().numpy()\n",
    "                y_true.append(true)\n",
    "\n",
    "        #  val stat evaluation   \n",
    "        y_true = np.concatenate(y_true , axis=0)\n",
    "        y_pred = np.concatenate(y_pred,  axis=0)\n",
    "        val_f1 = f1_score(y_true=y_true,y_pred=y_pred, average='macro')\n",
    "        val_acc = accuracy_score(y_true,y_pred)\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Save the best param\n",
    "        if val_f1 > best_f1:\n",
    "            best_f1 = val_f1\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                \n",
    "        # Print stat every 5 epoch\n",
    "        if (epoch+1)%5 == 0:\n",
    "            print(f'epoch: {epoch + 1}')\n",
    "            print(f'train_loss: {train_loss:.3f} val_loss: {val_loss:.3f} train_f1: {train_f1:.2f} val_fl: {val_f1:.3f}')\n",
    "\n",
    "    torch.save(net.state_dict(), './train_esm.pth')\n",
    "#    Load the best param\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    print(f'Best f1 score is {best_f1:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5efce13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-18T07:51:28.459464Z",
     "iopub.status.busy": "2023-03-18T07:51:28.459170Z",
     "iopub.status.idle": "2023-03-18T07:53:04.231364Z",
     "shell.execute_reply": "2023-03-18T07:53:04.230294Z"
    },
    "papermill": {
     "duration": 95.778828,
     "end_time": "2023-03-18T07:53:04.234275",
     "exception": false,
     "start_time": "2023-03-18T07:51:28.455447",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5\n",
      "train_loss: 8.852 val_loss: 2.832 train_f1: 0.96 val_fl: 0.946\n",
      "epoch: 10\n",
      "train_loss: 4.829 val_loss: 2.792 train_f1: 0.97 val_fl: 0.956\n",
      "epoch: 15\n",
      "train_loss: 2.790 val_loss: 4.545 train_f1: 0.98 val_fl: 0.940\n",
      "epoch: 20\n",
      "train_loss: 3.292 val_loss: 3.506 train_f1: 0.98 val_fl: 0.943\n",
      "epoch: 25\n",
      "train_loss: 3.269 val_loss: 3.451 train_f1: 0.98 val_fl: 0.960\n",
      "epoch: 30\n",
      "train_loss: 2.172 val_loss: 3.574 train_f1: 0.98 val_fl: 0.963\n",
      "epoch: 35\n",
      "train_loss: 1.894 val_loss: 4.033 train_f1: 0.99 val_fl: 0.960\n",
      "epoch: 40\n",
      "train_loss: 2.010 val_loss: 3.751 train_f1: 0.98 val_fl: 0.966\n",
      "epoch: 45\n",
      "train_loss: 2.362 val_loss: 3.872 train_f1: 0.98 val_fl: 0.960\n",
      "epoch: 50\n",
      "train_loss: 1.975 val_loss: 3.694 train_f1: 0.99 val_fl: 0.962\n",
      "epoch: 55\n",
      "train_loss: 0.708 val_loss: 3.836 train_f1: 0.99 val_fl: 0.970\n",
      "epoch: 60\n",
      "train_loss: 0.704 val_loss: 4.045 train_f1: 0.99 val_fl: 0.971\n",
      "epoch: 65\n",
      "train_loss: 0.672 val_loss: 4.012 train_f1: 0.99 val_fl: 0.970\n",
      "epoch: 70\n",
      "train_loss: 0.620 val_loss: 4.162 train_f1: 0.99 val_fl: 0.968\n",
      "epoch: 75\n",
      "train_loss: 0.652 val_loss: 4.181 train_f1: 0.99 val_fl: 0.969\n",
      "epoch: 80\n",
      "train_loss: 0.640 val_loss: 4.237 train_f1: 0.99 val_fl: 0.971\n",
      "epoch: 85\n",
      "train_loss: 0.636 val_loss: 4.092 train_f1: 0.99 val_fl: 0.971\n",
      "epoch: 90\n",
      "train_loss: 0.580 val_loss: 4.339 train_f1: 0.99 val_fl: 0.970\n",
      "epoch: 95\n",
      "train_loss: 0.581 val_loss: 4.310 train_f1: 0.99 val_fl: 0.970\n",
      "epoch: 100\n",
      "train_loss: 0.555 val_loss: 4.565 train_f1: 0.99 val_fl: 0.968\n",
      "epoch: 105\n",
      "train_loss: 0.434 val_loss: 4.648 train_f1: 0.99 val_fl: 0.971\n",
      "epoch: 110\n",
      "train_loss: 0.417 val_loss: 4.771 train_f1: 0.99 val_fl: 0.971\n",
      "epoch: 115\n",
      "train_loss: 0.409 val_loss: 4.868 train_f1: 0.99 val_fl: 0.971\n",
      "epoch: 120\n",
      "train_loss: 0.402 val_loss: 4.906 train_f1: 0.99 val_fl: 0.971\n",
      "epoch: 125\n",
      "train_loss: 0.395 val_loss: 4.949 train_f1: 0.99 val_fl: 0.971\n",
      "epoch: 130\n",
      "train_loss: 0.377 val_loss: 4.979 train_f1: 0.99 val_fl: 0.971\n",
      "epoch: 135\n",
      "train_loss: 0.378 val_loss: 5.071 train_f1: 0.99 val_fl: 0.970\n",
      "epoch: 140\n",
      "train_loss: 0.353 val_loss: 5.154 train_f1: 0.99 val_fl: 0.971\n",
      "epoch: 145\n",
      "train_loss: 0.347 val_loss: 5.251 train_f1: 0.99 val_fl: 0.969\n",
      "epoch: 150\n",
      "train_loss: 0.347 val_loss: 5.281 train_f1: 0.99 val_fl: 0.971\n",
      "epoch: 155\n",
      "train_loss: 0.300 val_loss: 5.326 train_f1: 1.00 val_fl: 0.971\n",
      "epoch: 160\n",
      "train_loss: 0.298 val_loss: 5.340 train_f1: 1.00 val_fl: 0.971\n",
      "epoch: 165\n",
      "train_loss: 0.296 val_loss: 5.364 train_f1: 1.00 val_fl: 0.971\n",
      "epoch: 170\n",
      "train_loss: 0.296 val_loss: 5.387 train_f1: 0.99 val_fl: 0.971\n",
      "epoch: 175\n",
      "train_loss: 0.291 val_loss: 5.407 train_f1: 1.00 val_fl: 0.971\n",
      "epoch: 180\n",
      "train_loss: 0.291 val_loss: 5.420 train_f1: 0.99 val_fl: 0.971\n",
      "epoch: 185\n",
      "train_loss: 0.287 val_loss: 5.444 train_f1: 1.00 val_fl: 0.971\n",
      "epoch: 190\n",
      "train_loss: 0.290 val_loss: 5.462 train_f1: 1.00 val_fl: 0.971\n",
      "epoch: 195\n",
      "train_loss: 0.296 val_loss: 5.475 train_f1: 1.00 val_fl: 0.971\n",
      "epoch: 200\n",
      "train_loss: 0.280 val_loss: 5.501 train_f1: 1.00 val_fl: 0.971\n",
      "Best f1 score is 0.973\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "if __name__ == '__main__':            \n",
    "    net = Net(num_classes=15)\n",
    "    net.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # optimizer = optim.SGD(net.parameters(), lr=0.005, momentum=0.9)\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "    lr_scheduler = lr_scheduler.StepLR(optimizer, step_size = 50, gamma=0.2)\n",
    "    model = train_model(net, criterion, optimizer, lr_scheduler, num_epochs=200)\n",
    "\n",
    "    # Load test data\n",
    "#     test_esm = torch.load('/kaggle/working/test.pt')\n",
    "    test_esm = torch.load('/kaggle/input/asm2-check-pt/aist4010 asm2/test.pt')\n",
    "    label = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in test_esm:\n",
    "            outputs = net(data.cuda())\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            label.append(predicted.cpu().numpy()[0])\n",
    "\n",
    "    results = {'id': test_list, 'label': label}\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 122.662699,
   "end_time": "2023-03-18T07:53:05.563008",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-03-18T07:51:02.900309",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
